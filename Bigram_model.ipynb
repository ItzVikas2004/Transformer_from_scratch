{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12214980,"sourceType":"datasetVersion","datasetId":7695239},{"sourceId":12217676,"sourceType":"datasetVersion","datasetId":7697157}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:32.798072Z","iopub.execute_input":"2025-07-04T19:39:32.798911Z","iopub.status.idle":"2025-07-04T19:39:32.822600Z","shell.execute_reply.started":"2025-07-04T19:39:32.798882Z","shell.execute_reply":"2025-07-04T19:39:32.821670Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/new-input/huge_training_text.txt\n/kaggle/input/input-1/input.txt\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:38.516767Z","iopub.execute_input":"2025-07-04T19:39:38.517062Z","iopub.status.idle":"2025-07-04T19:39:38.522326Z","shell.execute_reply.started":"2025-07-04T19:39:38.517039Z","shell.execute_reply":"2025-07-04T19:39:38.521248Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"BATCH_SIZE = 16       # Number of sequences processed in parallel\nBLOCK_SIZE = 32       # Maximum context length for predictions\nMAX_ITERS = 5000      # Training iterations\nEVAL_INTERVAL = 100   # Interval to evaluate loss\nLEARNING_RATE = 1e-3  # Learning rate for optimizer\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nEVAL_ITERS = 200      # Iterations to estimate loss\nEMBED_DIM = 64        # Embedding dimension\nNUM_HEADS = 4         # Number of attention heads\nNUM_LAYERS = 4        # Number of Transformer blocks\nDROPOUT = 0.0         # Dropout probability\n\ntorch.manual_seed(1337)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:42.328989Z","iopub.execute_input":"2025-07-04T19:39:42.329689Z","iopub.status.idle":"2025-07-04T19:39:42.346746Z","shell.execute_reply.started":"2025-07-04T19:39:42.329664Z","shell.execute_reply":"2025-07-04T19:39:42.345727Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f5e0fd3f0d0>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"with open('/kaggle/input/input-1/input.txt', 'r', encoding='utf-8') as f:\n     text = f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:47.515001Z","iopub.execute_input":"2025-07-04T19:39:47.515316Z","iopub.status.idle":"2025-07-04T19:39:47.520793Z","shell.execute_reply.started":"2025-07-04T19:39:47.515294Z","shell.execute_reply":"2025-07-04T19:39:47.519972Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:50.274974Z","iopub.execute_input":"2025-07-04T19:39:50.275267Z","iopub.status.idle":"2025-07-04T19:39:50.292971Z","shell.execute_reply.started":"2025-07-04T19:39:50.275248Z","shell.execute_reply":"2025-07-04T19:39:50.292023Z"}},"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:53.761362Z","iopub.execute_input":"2025-07-04T19:39:53.761630Z","iopub.status.idle":"2025-07-04T19:39:53.769157Z","shell.execute_reply.started":"2025-07-04T19:39:53.761613Z","shell.execute_reply":"2025-07-04T19:39:53.768317Z"}},"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"import torch # we use PyTorch: https://pytorch.org\ndata = torch.tensor(encode(text), dtype=torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:39:56.811686Z","iopub.execute_input":"2025-07-04T19:39:56.811983Z","iopub.status.idle":"2025-07-04T19:39:57.004557Z","shell.execute_reply.started":"2025-07-04T19:39:56.811960Z","shell.execute_reply":"2025-07-04T19:39:57.003606Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1115394]) torch.int64\ntensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"# Let's now split up the data into train and validation sets\nn = int(0.9*len(data)) # first 90% will be train, rest val\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:03.300090Z","iopub.execute_input":"2025-07-04T19:40:03.300448Z","iopub.status.idle":"2025-07-04T19:40:03.306245Z","shell.execute_reply.started":"2025-07-04T19:40:03.300424Z","shell.execute_reply":"2025-07-04T19:40:03.305268Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:06.119316Z","iopub.execute_input":"2025-07-04T19:40:06.119658Z","iopub.status.idle":"2025-07-04T19:40:06.126989Z","shell.execute_reply.started":"2025-07-04T19:40:06.119631Z","shell.execute_reply":"2025-07-04T19:40:06.125967Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:09.315432Z","iopub.execute_input":"2025-07-04T19:40:09.316186Z","iopub.status.idle":"2025-07-04T19:40:09.324037Z","shell.execute_reply.started":"2025-07-04T19:40:09.316131Z","shell.execute_reply":"2025-07-04T19:40:09.323053Z"}},"outputs":[{"name":"stdout","text":"when input is tensor([18]) the target: 47\nwhen input is tensor([18, 47]) the target: 56\nwhen input is tensor([18, 47, 56]) the target: 57\nwhen input is tensor([18, 47, 56, 57]) the target: 58\nwhen input is tensor([18, 47, 56, 57, 58]) the target: 1\nwhen input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\nwhen input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\nwhen input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"torch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\n\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    return x, y\n\nxb, yb = get_batch('train')\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\nprint('----')\n\nfor b in range(batch_size): # batch dimension\n    for t in range(block_size): # time dimension\n        context = xb[b, :t+1]\n        target = yb[b,t]\n        print(f\"when input is {context.tolist()} the target: {target}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:12.812506Z","iopub.execute_input":"2025-07-04T19:40:12.812854Z","iopub.status.idle":"2025-07-04T19:40:12.830496Z","shell.execute_reply.started":"2025-07-04T19:40:12.812833Z","shell.execute_reply":"2025-07-04T19:40:12.829430Z"}},"outputs":[{"name":"stdout","text":"inputs:\ntorch.Size([4, 8])\ntensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\ntargets:\ntorch.Size([4, 8])\ntensor([[43, 58,  5, 57,  1, 46, 43, 39],\n        [53, 56,  1, 58, 46, 39, 58,  1],\n        [58,  1, 58, 46, 39, 58,  1, 46],\n        [17, 27, 10,  0, 21,  1, 54, 39]])\n----\nwhen input is [24] the target: 43\nwhen input is [24, 43] the target: 58\nwhen input is [24, 43, 58] the target: 5\nwhen input is [24, 43, 58, 5] the target: 57\nwhen input is [24, 43, 58, 5, 57] the target: 1\nwhen input is [24, 43, 58, 5, 57, 1] the target: 46\nwhen input is [24, 43, 58, 5, 57, 1, 46] the target: 43\nwhen input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\nwhen input is [44] the target: 53\nwhen input is [44, 53] the target: 56\nwhen input is [44, 53, 56] the target: 1\nwhen input is [44, 53, 56, 1] the target: 58\nwhen input is [44, 53, 56, 1, 58] the target: 46\nwhen input is [44, 53, 56, 1, 58, 46] the target: 39\nwhen input is [44, 53, 56, 1, 58, 46, 39] the target: 58\nwhen input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\nwhen input is [52] the target: 58\nwhen input is [52, 58] the target: 1\nwhen input is [52, 58, 1] the target: 58\nwhen input is [52, 58, 1, 58] the target: 46\nwhen input is [52, 58, 1, 58, 46] the target: 39\nwhen input is [52, 58, 1, 58, 46, 39] the target: 58\nwhen input is [52, 58, 1, 58, 46, 39, 58] the target: 1\nwhen input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\nwhen input is [25] the target: 17\nwhen input is [25, 17] the target: 27\nwhen input is [25, 17, 27] the target: 10\nwhen input is [25, 17, 27, 10] the target: 0\nwhen input is [25, 17, 27, 10, 0] the target: 21\nwhen input is [25, 17, 27, 10, 0, 21] the target: 1\nwhen input is [25, 17, 27, 10, 0, 21, 1] the target: 54\nwhen input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"print(xb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:17.961513Z","iopub.execute_input":"2025-07-04T19:40:17.961842Z","iopub.status.idle":"2025-07-04T19:40:17.967797Z","shell.execute_reply.started":"2025-07-04T19:40:17.961817Z","shell.execute_reply":"2025-07-04T19:40:17.966950Z"}},"outputs":[{"name":"stdout","text":"tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n        [44, 53, 56,  1, 58, 46, 39, 58],\n        [52, 58,  1, 58, 46, 39, 58,  1],\n        [25, 17, 27, 10,  0, 21,  1, 54]])\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)\n\nclass BigramLanguageModel(nn.Module):\n\n    def __init__(self, vocab_size):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n\n    def forward(self, idx, targets=None):\n\n        # idx and targets are both (B,T) tensor of integers\n        logits = self.token_embedding_table(idx) # (B,T,C)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # get the predictions\n            logits, loss = self(idx)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nm = BigramLanguageModel(vocab_size)\nlogits, loss = m(xb, yb)\nprint(logits.shape)\nprint(loss)\n\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:20.129404Z","iopub.execute_input":"2025-07-04T19:40:20.129669Z","iopub.status.idle":"2025-07-04T19:40:20.174902Z","shell.execute_reply.started":"2025-07-04T19:40:20.129651Z","shell.execute_reply":"2025-07-04T19:40:20.174052Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 65])\ntensor(4.8786, grad_fn=<NllLossBackward0>)\n\nSr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# create a PyTorch optimizer\noptimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:26.063785Z","iopub.execute_input":"2025-07-04T19:40:26.064068Z","iopub.status.idle":"2025-07-04T19:40:26.068530Z","shell.execute_reply.started":"2025-07-04T19:40:26.064046Z","shell.execute_reply":"2025-07-04T19:40:26.067575Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"batch_size = 32\nfor steps in range(5000): # increase number of steps for good results...\n\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    logits, loss = m(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\nprint(loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:29.426630Z","iopub.execute_input":"2025-07-04T19:40:29.427371Z","iopub.status.idle":"2025-07-04T19:40:38.291558Z","shell.execute_reply.started":"2025-07-04T19:40:29.427335Z","shell.execute_reply":"2025-07-04T19:40:38.290700Z"}},"outputs":[{"name":"stdout","text":"2.6809184551239014\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=2000)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:46.727867Z","iopub.execute_input":"2025-07-04T19:40:46.728129Z","iopub.status.idle":"2025-07-04T19:40:47.083877Z","shell.execute_reply.started":"2025-07-04T19:40:46.728111Z","shell.execute_reply":"2025-07-04T19:40:47.082973Z"}},"outputs":[{"name":"stdout","text":"\nMavanghtang d wsramangT:\nD: nd TINT:\nFof;AURKIfediTus, be:ghere\nDyo.O'd, t fed inks cerVis benes. owepwnof pre, athar wowir W:\nALI u\nBue;bOgfatho rend thic; is be wara!\nPO.\nWGListh R.\nJO:\nTERI! ce, ince:'\nt.\nSin honk$zlerseestindovrer wat boue nodgh flle, mOM:\n\nSCKpoto AKIFwinthind d me sesete gkerw'DWhe arDERe\n\nHET:\nROLINanxueile to he bis wllagGomieg.\nDWhelat s tropghallll,\nWh trnenQJMmllel $fupat iBOFokKENor-mu ed de atos are th, a!Oun my s l:\nE-de pond\nTII'henJAllong bogave tthe s me : t\nYo-le m blo s;p; t;.RIUEWhisthast Q!\nAn thinencort s d aind Rj, A:, We OOkze mak.\nLy i\nWh ths wNThiveas t fye tea;\nFls kGoncaset'Y:CARxBun my rite e tle?ONzos DUGRSaId a atororetheang nSALERCHees inowif?pr\n'thin ICAnd'd digry mves twhatl f tthe y wey y pe, bedomerzio, or m, stlly il, ilve. outhereSBHAgicesed muspatofat wo d gR tyJke garavenpry d Wenoumy f the'dha ipg:\nNOn s mave, eve s feAR:\nHoford pesisShire tearor-tam de\nFRIs woCEs Yeandst h lldolor g brit 'd yUTq-lk&ven'-uth t, ve!\nRak theto ty ond therewNASbe h s&d\nASkr h, lpMpealousrtomellfibeporthociO, ilddod,\nO:\nIVYCasn t hore br fore\nCIA sis tuly gek makithONI'e oth, athajumphe fing ie\nWe nd\nWerdy ly fin ento, meston, nTharq-ck.\nENoorindscqverQ-gadayVernd,&Boux?I'd, k e tghentyowilenet imerg l--mof W'd iathe!\n\nINLin y I&on ot, w tritwe s sim ow rderingemes de therer dedes mf--tothe.\nSVINCKUSim, wofe thampu tatpll?K:\nA IJUNAURUER:\n\nThakaSe as f A-vefk rthishAy t therQulinERKITblooocooreay hul y d-d the!\n\nATTIUptor tooms llire My mvemn Be\nSer y;K:rdmurmbun\n\nWASfubenJUElly t y BANGBOXE richave\nI, mofoff zas, IUForse. reenangdadindenxEOreasldum,\n\n\ne\nYolfffitld, bl'ere er:\nBLenEr w\nSe, WWhes jFYNapay tethore!uE:\nGLBedofubl'VOKuit!\nSit LINCL:\nIZKII R.\ntr han:\nTheaseise athicof\nLOLBus CERYde tDesula tttithe lour wes kisasiseaUTw?Oinounera tlantUFKGave\nIBFr nein t;AUBo p$s\nI& 'switoud su, r t ide\nxxatqe f boo te tt, ho morved'WAce t f Vn?k:\nKIOWoid,\nVORKoy CHAneyed ng princr whe, dme yFoouthyVOy\nARGongas:\nTIDUEn t$YCVOUCKIOPaus \n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\ntorch.manual_seed(42)\na = torch.tril(torch.ones(3, 3))\na = a / torch.sum(a, 1, keepdim=True)\nb = torch.randint(0,10,(3,2)).float()\nc = a @ b\nprint('a=')\nprint(a)\nprint('--')\nprint('b=')\nprint(b)\nprint('--')\nprint('c=')\nprint(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:50.962787Z","iopub.execute_input":"2025-07-04T19:40:50.963606Z","iopub.status.idle":"2025-07-04T19:40:50.977222Z","shell.execute_reply.started":"2025-07-04T19:40:50.963530Z","shell.execute_reply":"2025-07-04T19:40:50.976208Z"}},"outputs":[{"name":"stdout","text":"a=\ntensor([[1.0000, 0.0000, 0.0000],\n        [0.5000, 0.5000, 0.0000],\n        [0.3333, 0.3333, 0.3333]])\n--\nb=\ntensor([[2., 7.],\n        [6., 4.],\n        [6., 5.]])\n--\nc=\ntensor([[2.0000, 7.0000],\n        [4.0000, 5.5000],\n        [4.6667, 5.3333]])\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"# consider the following toy example:\n\ntorch.manual_seed(1337)\nB,T,C = 4,8,2 # batch, time, channels\nx = torch.randn(B,T,C)\nx.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:53.726825Z","iopub.execute_input":"2025-07-04T19:40:53.727454Z","iopub.status.idle":"2025-07-04T19:40:53.735332Z","shell.execute_reply.started":"2025-07-04T19:40:53.727430Z","shell.execute_reply":"2025-07-04T19:40:53.734534Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 8, 2])"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"# We want x[b,t] = mean_{i<=t} x[b,i]\nxbow = torch.zeros((B,T,C))\nfor b in range(B):\n    for t in range(T):\n        xprev = x[b,:t+1] # (t,C)\n        xbow[b,t] = torch.mean(xprev, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:40:56.290132Z","iopub.execute_input":"2025-07-04T19:40:56.290828Z","iopub.status.idle":"2025-07-04T19:40:56.297041Z","shell.execute_reply.started":"2025-07-04T19:40:56.290789Z","shell.execute_reply":"2025-07-04T19:40:56.296209Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"# version 2: using matrix multiply for a weighted aggregation\nwei = torch.tril(torch.ones(T, T))\nwei = wei / wei.sum(1, keepdim=True)\nxbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\ntorch.allclose(xbow, xbow2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:00.443474Z","iopub.execute_input":"2025-07-04T19:41:00.443764Z","iopub.status.idle":"2025-07-04T19:41:00.452818Z","shell.execute_reply.started":"2025-07-04T19:41:00.443743Z","shell.execute_reply":"2025-07-04T19:41:00.451852Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"# version 3: use Softmax\ntril = torch.tril(torch.ones(T, T))\nwei = torch.zeros((T,T))\nwei = wei.masked_fill(tril == 0, float('-inf'))\nwei = F.softmax(wei, dim=-1)\nxbow3 = wei @ x\ntorch.allclose(xbow, xbow3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:02.586262Z","iopub.execute_input":"2025-07-04T19:41:02.586893Z","iopub.status.idle":"2025-07-04T19:41:02.594621Z","shell.execute_reply.started":"2025-07-04T19:41:02.586867Z","shell.execute_reply":"2025-07-04T19:41:02.593881Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"# version 4: self-attention!\ntorch.manual_seed(1337)\nB,T,C = 4,8,32 # batch, time, channels\nx = torch.randn(B,T,C)\n\n# let's see a single Head perform self-attention\nhead_size = 16\nkey = nn.Linear(C, head_size, bias=False)\nquery = nn.Linear(C, head_size, bias=False)\nvalue = nn.Linear(C, head_size, bias=False)\nk = key(x)   # (B, T, 16)\nq = query(x) # (B, T, 16)\nwei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n\ntril = torch.tril(torch.ones(T, T))\n#wei = torch.zeros((T,T))\nwei = wei.masked_fill(tril == 0, float('-inf'))\nwei = F.softmax(wei, dim=-1)\n\nv = value(x)\nout = wei @ v\n#out = wei @ x\n\nout.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:05.950705Z","iopub.execute_input":"2025-07-04T19:41:05.951312Z","iopub.status.idle":"2025-07-04T19:41:05.963697Z","shell.execute_reply.started":"2025-07-04T19:41:05.951288Z","shell.execute_reply":"2025-07-04T19:41:05.962970Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 8, 16])"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"wei[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:10.063789Z","iopub.execute_input":"2025-07-04T19:41:10.064454Z","iopub.status.idle":"2025-07-04T19:41:10.071444Z","shell.execute_reply.started":"2025-07-04T19:41:10.064429Z","shell.execute_reply":"2025-07-04T19:41:10.070637Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n       grad_fn=<SelectBackward0>)"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"k = torch.randn(B,T,head_size)\nq = torch.randn(B,T,head_size)\nwei = q @ k.transpose(-2, -1) * head_size**-0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:15.923834Z","iopub.execute_input":"2025-07-04T19:41:15.924131Z","iopub.status.idle":"2025-07-04T19:41:15.930043Z","shell.execute_reply.started":"2025-07-04T19:41:15.924109Z","shell.execute_reply":"2025-07-04T19:41:15.929064Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"k.var()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:18.978564Z","iopub.execute_input":"2025-07-04T19:41:18.979184Z","iopub.status.idle":"2025-07-04T19:41:18.985939Z","shell.execute_reply.started":"2025-07-04T19:41:18.979142Z","shell.execute_reply":"2025-07-04T19:41:18.985146Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"tensor(1.0449)"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"q.var()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:20.986688Z","iopub.execute_input":"2025-07-04T19:41:20.986976Z","iopub.status.idle":"2025-07-04T19:41:20.993975Z","shell.execute_reply.started":"2025-07-04T19:41:20.986958Z","shell.execute_reply":"2025-07-04T19:41:20.992842Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"tensor(1.0700)"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"wei.var()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:23.320994Z","iopub.execute_input":"2025-07-04T19:41:23.321517Z","iopub.status.idle":"2025-07-04T19:41:23.328452Z","shell.execute_reply.started":"2025-07-04T19:41:23.321490Z","shell.execute_reply":"2025-07-04T19:41:23.327606Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"tensor(1.0918)"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:25.688772Z","iopub.execute_input":"2025-07-04T19:41:25.689408Z","iopub.status.idle":"2025-07-04T19:41:25.696043Z","shell.execute_reply.started":"2025-07-04T19:41:25.689377Z","shell.execute_reply":"2025-07-04T19:41:25.695336Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:28.733552Z","iopub.execute_input":"2025-07-04T19:41:28.733825Z","iopub.status.idle":"2025-07-04T19:41:28.740975Z","shell.execute_reply.started":"2025-07-04T19:41:28.733807Z","shell.execute_reply":"2025-07-04T19:41:28.740205Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"class LayerNorm1d: # (used to be BatchNorm1d)\n\n  def __init__(self, dim, eps=1e-5, momentum=0.1):\n    self.eps = eps\n    self.gamma = torch.ones(dim)\n    self.beta = torch.zeros(dim)\n\n  def __call__(self, x):\n    # calculate the forward pass\n    xmean = x.mean(1, keepdim=True) # batch mean\n    xvar = x.var(1, keepdim=True) # batch variance\n    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n    self.out = self.gamma * xhat + self.beta\n    return self.out\n\n  def parameters(self):\n    return [self.gamma, self.beta]\n\ntorch.manual_seed(1337)\nmodule = LayerNorm1d(100)\nx = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\nx = module(x)\nx.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:30.870722Z","iopub.execute_input":"2025-07-04T19:41:30.871004Z","iopub.status.idle":"2025-07-04T19:41:30.884553Z","shell.execute_reply.started":"2025-07-04T19:41:30.870987Z","shell.execute_reply":"2025-07-04T19:41:30.883586Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 100])"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"x[:,0].mean(), x[:,0].std()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:34.685543Z","iopub.execute_input":"2025-07-04T19:41:34.685883Z","iopub.status.idle":"2025-07-04T19:41:34.693465Z","shell.execute_reply.started":"2025-07-04T19:41:34.685857Z","shell.execute_reply":"2025-07-04T19:41:34.692588Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"(tensor(0.1469), tensor(0.8803))"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:37.905099Z","iopub.execute_input":"2025-07-04T19:41:37.905957Z","iopub.status.idle":"2025-07-04T19:41:37.913017Z","shell.execute_reply.started":"2025-07-04T19:41:37.905927Z","shell.execute_reply":"2025-07-04T19:41:37.912203Z"}},"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"(tensor(-9.5367e-09), tensor(1.0000))"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=2000)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:40.210746Z","iopub.execute_input":"2025-07-04T19:41:40.211017Z","iopub.status.idle":"2025-07-04T19:41:40.544190Z","shell.execute_reply.started":"2025-07-04T19:41:40.211000Z","shell.execute_reply":"2025-07-04T19:41:40.543231Z"}},"outputs":[{"name":"stdout","text":"\nF.\nS: hemishovicak!\nUCKAKENCILIfort--KIO'Thustubmbastystathousad&-Th$?YGRTbri Thave ors, avm, ces lH:\nO p\nf blus gaqlon l:\nHAULO for Ithe !Boobeau\n\nI,\nBus hea k-NRINstgn st w s\nFoshe bQbrthllclal y he;\nr-the,s, ss:\nFUSVHUke don celkngze nges,\nFinXSPIUvell wacPIof athaiseg od ck!\n\nP,\nDY:CJWelgis oESn AUSSELALENpstheranit MgRl thibod to kcacq.int th gino il o glline coues icar tate\nI'tim thersor f sre s CHethes fu, itooust:\nS:\nTRWce a-mere, w ad fowin.\nD:\nKEighenore quserd mVPHiveDWiesianzellape myb the adan d g!\n\nDIUETh my.\n\nWry cheanotavehy bemancooce I i, imecerok fr:\nNInowainpew3f?\nTARMu ffXe y.\nIDqkindI hont Ifot'dLYDuy menDiTowneve's o ouese tRgC $\n\nDbliuar bOKormeq.\nom, CIst may wo m\nAy.\n\nY:\nAThapm th Fr;3s thard achrot-ncUzoul war 'sanoubomormexk tel!\n\nKIOMo y'th\nDoneherrehicke,Yeravat e at an'dV:\nCESthidstheind LI&ENSqMA'e eGoyino sh weZYon he,\n\nBs to fouspag idd ouamy.\nO:\npixar I' forot thSPye, al INGUCUM? Iforat pe, ft ofxnhand.\nPantres surzXExOMbe bral q$ZMkin V: as pe\n'd d timy\nTh iopaver I lt&FRey llis tky LCHo alis?qP-ot thothe DugOLAR'd ovee hs s fixaths w,\nAERSPitou$vestes$zeere e k ang hFCLLAila.\nTiDULA gst nd bfepree y atSrs arat!\n\nwWharixbllise hary tharis\nJu$Whale br-g sted whifr f, onnle,\nth$LUCOres carde ve t far-hliqu t qHo tuenee. as i--tins.\nI mpJO!\nSo's\nGersMPy'hathhe.\nMI all\nENCIDORIn\nAn CHx?wares haut uso I fFos ty aNwime alazavene'd athepak dersy CVjay.\n\nCETs-bes sth sad or s; f f sio swales epxavenYue.\nBy.\nhnsargooor w towis Be, ty?,MPbelld, f ie mo mesoin llof yedmo'dhakne,\nAkyora pbodea ERARIUEvendommy tano nd lla!USe idirgrt;\nAnond blizYonead ye'a-vetongef ilf.\nF ga' sth ar tatXlciratiee.\nESCHA banbyoowASkcoo'd.\n\nT:\nThifard,STopowins itsmy e halaig ; hophitt o th oombeer gillererJF thake t spukessa--SSankealll?lld\nIVthas:3KEL: ZAl If tTE-wintherit ly, bldende,\nFd l:\nInke;RSLTbhic?\nTas, b;\nRIOLEHEve,sor g as kest an'er.\npth wJUSPlaj$Ord, RIfusrond ine agFl y ntiWhe flore fe; teno ther th.\nI re w ho tt fo CHEan ha INCAse ik thene hind; \n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"import torch\n\n\ncontext = \"com\"\n\n\ncontext_ids = torch.tensor([encode(context)], dtype=torch.long)\nprint(f\"Encoded context: {context_ids}\")\n\n\noutput = m.generate(idx=context_ids, max_new_tokens=1)\n\nnext_char_id = output[0][-1].item()\nnext_char = decode([next_char_id])\n\nprint(f\"Given '{context}' => Next character predicted: '{next_char}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:45.721306Z","iopub.execute_input":"2025-07-04T19:41:45.721596Z","iopub.status.idle":"2025-07-04T19:41:45.729920Z","shell.execute_reply.started":"2025-07-04T19:41:45.721573Z","shell.execute_reply":"2025-07-04T19:41:45.728997Z"}},"outputs":[{"name":"stdout","text":"Encoded context: tensor([[41, 53, 51]])\nGiven 'com' => Next character predicted: 'i'\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"@torch.no_grad()\ndef test_accuracy(split='val', num_batches=100):\n    m.eval()\n    total = 0\n    correct = 0\n\n    for _ in range(num_batches):\n        xb, yb = get_batch(split)  # (B,T)\n        logits, _ = m(xb)  # (B,T,C)\n        preds = torch.argmax(logits, dim=-1)  # (B,T)\n        correct += (preds == yb).sum().item()\n        total += preds.numel()\n\n    acc = correct / total\n    print(f\"{split} accuracy: {acc:.4f}\")\n    return acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:49.021032Z","iopub.execute_input":"2025-07-04T19:41:49.021829Z","iopub.status.idle":"2025-07-04T19:41:49.028667Z","shell.execute_reply.started":"2025-07-04T19:41:49.021801Z","shell.execute_reply":"2025-07-04T19:41:49.027664Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"test_accuracy(split='val', num_batches=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:41:53.441520Z","iopub.execute_input":"2025-07-04T19:41:53.441811Z","iopub.status.idle":"2025-07-04T19:41:53.568992Z","shell.execute_reply.started":"2025-07-04T19:41:53.441790Z","shell.execute_reply":"2025-07-04T19:41:53.568241Z"}},"outputs":[{"name":"stdout","text":"val accuracy: 0.2674\n","output_type":"stream"},{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"0.2673828125"},"metadata":{}}],"execution_count":106}]}